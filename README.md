# ğŸ“Š Real-Time Data Processing System

![Dashboard Preview](img/dashboard_img.png)

Sistema completo de processamento e visualizaÃ§Ã£o de dados em tempo real que monitora um arquivo CSV, processa via Kafka e exibe os dados em um dashboard interativo usando Streamlit.

## ğŸ¯ Funcionalidades Principais

âœ… **Dashboard Interativo**: Interface web moderna com Streamlit  
âœ… **Tempo Real**: AtualizaÃ§Ã£o automÃ¡tica a cada 3 segundos  
âœ… **VisualizaÃ§Ãµes Ricas**: GrÃ¡ficos de barras, histogramas, pizza e scatter  
âœ… **MÃ©tricas DinÃ¢micas**: Valor total, mÃ©dio, contadores e estatÃ­sticas  
âœ… **Kafka Integration**: Processamento de dados via Apache Kafka  
âœ… **UI do Kafka**: Interface web moderna para monitorar tÃ³picos e mensagens (Kafka UI)  
âœ… **SincronizaÃ§Ã£o Completa**: RemoÃ§Ã£o de dados do CSV reflete no dashboard  
âœ… **Testes Automatizados**: Bateria completa de testes com pytest  
âœ… **100% Open Source**: Migrado para `kafka-python` (sem dependÃªncias proprietÃ¡rias)  
âœ… **FÃ¡cil de Usar**: Adicione/remova dados no CSV ou via UI e veja as mudanÃ§as instantaneamente  

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos
- **Docker & Docker Compose**: Para executar Kafka e serviÃ§os
- **Python 3.12+**: Para executar os scripts
- **UV**: Gerenciador de dependÃªncias Python moderno

### InstalaÃ§Ã£o do UV
```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Ou via pip
pip install uv

# Verificar instalaÃ§Ã£o
uv --version
```

### Setup Completo do Projeto

#### 1. Clonar o RepositÃ³rio
```bash
# Clonar o repositÃ³rio (substitua pela URL real)
git clone <URL_DO_REPOSITORIO>
cd real_time_data

# Ou se jÃ¡ tem o cÃ³digo localmente
cd caminho/para/real_time_data
```

#### 2. Criar e Configurar Ambiente Virtual
```bash
# Criar ambiente virtual e instalar dependÃªncias automaticamente
uv sync

# Isso vai:
# - Criar .venv/ no diretÃ³rio do projeto
# - Instalar Python 3.12+ se necessÃ¡rio
# - Instalar todas as dependÃªncias do pyproject.toml
```

#### 3. Ativar Ambiente Virtual (Opcional)
```bash
# OpÃ§Ã£o 1: Ativar manualmente (tradicional)
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows

# OpÃ§Ã£o 2: Usar uv run (recomendado - nÃ£o precisa ativar)
uv run python --version
uv run pip list
```

#### 4. Verificar InstalaÃ§Ã£o
```bash
# Com ambiente ativado
python --version
pip list

# Ou com uv run (sem ativar)
uv run python --version
uv run pip list

# Verificar dependÃªncias especÃ­ficas
uv run python -c "import kafka, streamlit, pandas, plotly; print('âœ… Todas as dependÃªncias OK!')"
```

### Executar o Sistema Completo

#### MÃ©todo 1: Com UV Run (Recomendado)
```bash
# Terminal 1: Iniciar infraestrutura Kafka
docker-compose up -d

# Aguardar 60-90 segundos para Kafka inicializar completamente

# Terminal 2: Executar o producer CSV
cd real_time_data
uv run python csv-monitor/csv_producer.py

# Terminal 3: Executar dashboard
cd real_time_data
uv run streamlit run streamlit/dashboard.py

# Acessar interfaces:
# ğŸ“Š Dashboard: http://localhost:8501
# ğŸ–¥ï¸ Kafka UI: http://localhost:8081
```

#### MÃ©todo 2: Com Ambiente Virtual Ativado
```bash
# Terminal 1: Kafka
docker-compose up -d

# Terminal 2: Ativar venv e executar producer
cd real_time_data
source .venv/bin/activate  # Linux/macOS
python csv-monitor/csv_producer.py

# Terminal 3: Ativar venv e executar dashboard
cd real_time_data
source .venv/bin/activate  # Linux/macOS
streamlit run streamlit/dashboard.py
```

### MÃ©todo Simples (Apenas Dashboard)
```bash
# 1. Executar apenas o dashboard
cd real_time_data
uv run streamlit run streamlit/dashboard.py

# 2. Abrir no navegador
# http://localhost:8501

# 3. Testar adicionando dados
echo "8,Roberto,45,Fortaleza,275.50" >> data/input.csv
```

## ğŸ“Š Dashboard Features

### MÃ©tricas em Tempo Real
- ğŸ’° **Valor Total**: Soma de todos os valores
- ğŸ“ˆ **Valor MÃ©dio**: MÃ©dia dos valores  
- ğŸ“‹ **Total Registros**: Quantidade de linhas
- ğŸ‘¥ **Idade MÃ©dia**: MÃ©dia das idades

### VisualizaÃ§Ãµes Interativas
- ğŸ“Š **GrÃ¡fico de Barras**: Valor por cidade
- ğŸ“ˆ **Histograma**: DistribuiÃ§Ã£o de idades  
- ğŸ¥§ **GrÃ¡fico de Pizza**: Percentual por cidade
- ğŸ” **Scatter Plot**: RelaÃ§Ã£o valor x idade

### Controles
- ğŸ”„ **Auto-refresh**: AtualizaÃ§Ã£o automÃ¡tica (3s)
- ğŸ—‘ï¸ **Limpar Cache**: Remove dados antigos do dashboard
- ğŸ“‹ **Tabelas DinÃ¢micas**: Dados completos e estatÃ­sticas
- ğŸ“„ **Info do Arquivo**: Metadados em tempo real

## ğŸ—ï¸ Arquitetura

### Arquitetura Completa (Atual)
```
ğŸ“ CSV File â†’ ğŸ” CSV Monitor â†’ ğŸ“¡ Kafka â†’ ğŸ“Š Dashboard
    â†“              â†“              â†“         â†“
data/input.csv â†’ csv_producer.py â†’ Topic â†’ Streamlit
                                    â†“
                              ğŸ–¥ï¸ Kafka UI (Management)
```

### Fluxo de Dados
1. **CSV Monitor** detecta mudanÃ§as no arquivo `data/input.csv`
2. **Producer** envia dados para o tÃ³pico Kafka `csv-data` usando `kafka-python`
3. **Dashboard** consome dados do Kafka em tempo real usando `KafkaConsumer`
4. **Kafka UI** permite monitorar tÃ³picos e inserir dados manualmente
5. **Reset AutomÃ¡tico**: Quando dados sÃ£o removidos do CSV, envia comando de reset

### Stack TecnolÃ³gica
```
Frontend:     Streamlit + Plotly
Backend:      Python 3.12 + kafka-python
Streaming:    Apache Kafka + Zookeeper
Management:   Kafka UI (Provectus)
Infra:        Docker Compose
Testing:      pytest + Mock
Dependencies: UV (Python package manager)
```

## ğŸ“ Estrutura do Projeto

```
real_time_data/
â”œâ”€â”€ ğŸ“‚ streamlit/           # Dashboard principal
â”‚   â””â”€â”€ dashboard.py        # Interface web Streamlit
â”œâ”€â”€ ğŸ“‚ csv-monitor/         # Monitor e Producer Kafka
â”‚   â””â”€â”€ csv_producer.py     # Monitora CSV e envia para Kafka
â”œâ”€â”€ ğŸ“‚ data/               # Dados de entrada  
â”‚   â””â”€â”€ input.csv          # Arquivo CSV monitorado
â”œâ”€â”€ ğŸ“‚ tests/              # Testes automatizados
â”‚   â”œâ”€â”€ __init__.py        # Pacote de testes
â”‚   â”œâ”€â”€ test_csv_producer.py    # Testes do CSV producer
â”‚   â”œâ”€â”€ test_dashboard.py       # Testes do dashboard
â”‚   â””â”€â”€ test_integration.py     # Testes de integraÃ§Ã£o
â”œâ”€â”€ ğŸ“‚ img/                # Imagens da documentaÃ§Ã£o
â”‚   â””â”€â”€ dashboard_img.png   # Preview do dashboard
â”œâ”€â”€ ğŸ³ docker-compose.yml  # Infraestrutura (Kafka, Zookeeper, AKHQ)
â”œâ”€â”€ ğŸ“„ pyproject.toml      # DependÃªncias Python
â””â”€â”€ ğŸ“– README.md           # Esta documentaÃ§Ã£o
```

## ğŸ”§ ConfiguraÃ§Ã£o

### Formato do CSV
```csv
id,nome,idade,cidade,valor
1,JoÃ£o,25,SÃ£o Paulo,100.50
2,Maria,30,Rio de Janeir`o,200.75
```

### ServiÃ§os DisponÃ­veis
- **Dashboard Streamlit**: http://localhost:8501
- **Kafka UI**: http://localhost:8081
- **Kafka Broker**: localhost:9092  
- **Zookeeper**: localhost:2181

### Como Inserir/Remover Dados

#### Via CSV (AutomÃ¡tico)
```bash
# Adicionar nova linha no CSV
echo "11,Fernanda,29,Fortaleza,680.90" >> data/input.csv

# Remover dados (editar arquivo manualmente)
# O dashboard serÃ¡ automaticamente atualizado para refletir as mudanÃ§as
```

#### Via Kafka UI
1. Acesse http://localhost:8081
2. Clique em "Topics" â†’ "csv-data"
3. Clique em "Produce Message"
4. Use este formato JSON:
```json
{
  "id": 200,
  "nome": "Novo Usuario",
  "idade": 28,
  "cidade": "Recife",
  "valor": 450.00,
  "timestamp": "2025-08-27T12:00:00"
}
```

## ğŸ§ª Testes

O projeto inclui uma bateria completa de testes automatizados:

### Executar Todos os Testes
```bash
# Executar todos os testes
uv run pytest tests/ -v

# Executar com cobertura
uv add pytest-cov --dev
uv run pytest tests/ --cov=. --cov-report=html
```

### Testes EspecÃ­ficos
```bash
# Testes do CSV Producer
uv run pytest tests/test_csv_producer.py -v

# Testes do Dashboard  
uv run pytest tests/test_dashboard.py -v

# Testes de IntegraÃ§Ã£o
uv run pytest tests/test_integration.py -v
```

### Cobertura dos Testes
- âœ… **CSV Producer**: InicializaÃ§Ã£o, leitura de CSV, envio para Kafka
- âœ… **Dashboard**: Processamento de mensagens, deduplicaÃ§Ã£o, mÃ©tricas
- âœ… **IntegraÃ§Ã£o**: Fluxo completo, tratamento de erros, monitoramento

## ğŸ› ï¸ Tecnologias

### Backend & Processamento
- **Python 3.12+**: Linguagem principal
- **Apache Kafka**: Message broker para streaming de dados
- **kafka-python**: Cliente Kafka 100% open-source para Python
- **Pandas**: ManipulaÃ§Ã£o e anÃ¡lise de dados

### Frontend & VisualizaÃ§Ã£o
- **Streamlit**: Framework web para dashboards
- **Plotly**: GrÃ¡ficos interativos e responsivos
- **Kafka UI (Provectus)**: Interface web moderna para gerenciamento do Kafka

### Infraestrutura
- **Docker & Docker Compose**: ContainerizaÃ§Ã£o e orquestraÃ§Ã£o
- **Apache Zookeeper**: CoordenaÃ§Ã£o de serviÃ§os Kafka
- **UV**: Gerenciador de dependÃªncias Python moderno

### DependÃªncias Python (pyproject.toml)
```toml
[project]
dependencies = [
    "streamlit>=1.39.0",
    "pandas>=2.2.3",
    "plotly>=5.24.1",
    "kafka-python>=2.0.2"
]

[tool.uv]
dev-dependencies = [
    "pytest>=8.4.1",
    "pytest-mock>=3.14.0"
]
```

## ğŸ› Troubleshooting

### Kafka nÃ£o conecta
```bash
# Verificar se containers estÃ£o rodando
docker ps

# Ver logs dos serviÃ§os
docker logs kafka
docker logs kafka-ui
docker logs zookeeper

# Reiniciar serviÃ§os
docker-compose restart

# Limpar e reiniciar tudo
docker-compose down --remove-orphans
docker-compose up -d
```

### Clusters offline na Kafka UI
```bash
# Aguardar mais tempo para Kafka inicializar (60-90s)
docker logs kafka

# Verificar se Kafka estÃ¡ respondendo
telnet localhost 9092

# Se necessÃ¡rio, reiniciar
docker-compose restart kafka
```

### Dashboard nÃ£o atualiza
- Verifique se o CSV producer estÃ¡ rodando com `uv run`
- Confirme se hÃ¡ dados no tÃ³pico Kafka via Kafka UI (http://localhost:8081)
- Use o botÃ£o "ğŸ—‘ï¸ Limpar Cache" no dashboard
- Reinicie o dashboard: `uv run streamlit run streamlit/dashboard.py`

### Erro de dependÃªncias Python
```bash
# Reinstalar dependÃªncias
uv sync --reinstall

# Verificar ambiente virtual
uv run python --version
uv run pip list

# Se usar Python global, sempre use uv run
uv run python csv-monitor/csv_producer.py
```

### Dados removidos do CSV nÃ£o somem do dashboard
- O sistema envia comandos de reset automaticamente
- Use o botÃ£o "ğŸ—‘ï¸ Limpar Cache" se necessÃ¡rio
- Verifique se o CSV producer detectou a mudanÃ§a no arquivo

### Testes falhando
```bash
# Verificar dependÃªncias
uv sync

# Executar testes individualmente
uv run pytest tests/test_csv_producer.py -v -s

# Executar todos os testes
uv run pytest tests/ -v
```

### Porta jÃ¡ em uso
```bash
# Se porta 8081 estiver ocupada
docker-compose down
sudo lsof -i :8081
# Matar processo ou alterar porta no docker-compose.yml
```

## ğŸ¯ Casos de Uso

- ğŸ“Š **Monitoramento de Vendas**: Acompanhar vendas em tempo real
- ğŸ“ˆ **Dashboards Executivos**: MÃ©tricas para tomada de decisÃ£o  
- ğŸ” **AnÃ¡lise de Dados**: Explorar padrÃµes e tendÃªncias
- ğŸ“‹ **RelatÃ³rios DinÃ¢micos**: RelatÃ³rios que se atualizam sozinhos

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Veja como:

1. Fork do projeto
2. Crie sua feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para detalhes.

---

## ğŸ‰ Resultado Final

### Interfaces DisponÃ­veis

1. **ğŸ“Š Dashboard Streamlit** (http://localhost:8501)
   - VisualizaÃ§Ãµes em tempo real
   - MÃ©tricas dinÃ¢micas
   - GrÃ¡ficos interativos
   - Controle de cache

2. **ğŸ–¥ï¸ Kafka UI** (http://localhost:8081)
   - Monitoramento de tÃ³picos e clusters
   - InserÃ§Ã£o manual de dados
   - VisualizaÃ§Ã£o de mensagens
   - Interface moderna e responsiva

### Status do Sistema
âœ… **Kafka**: Processamento de streaming com `kafka-python`  
âœ… **Dashboard**: VisualizaÃ§Ã£o em tempo real com Streamlit  
âœ… **CSV Monitor**: DetecÃ§Ã£o automÃ¡tica de mudanÃ§as no arquivo  
âœ… **SincronizaÃ§Ã£o**: RemoÃ§Ã£o de dados reflete no dashboard  
âœ… **UI Management**: Interface moderna para gerenciar dados  
âœ… **Testes**: Bateria completa de 9 testes automatizados  
âœ… **100% Open Source**: Sem dependÃªncias proprietÃ¡rias  

### Funcionalidades AvanÃ§adas
- ğŸ”„ **Reset AutomÃ¡tico**: Quando dados sÃ£o removidos do CSV, o dashboard Ã© limpo automaticamente
- ğŸ§ª **Testes Completos**: 9 testes cobrindo todas as funcionalidades principais
- ğŸ—‘ï¸ **Controle Manual**: BotÃ£o para limpar cache quando necessÃ¡rio
- ğŸ“Š **MÃ©tricas Precisas**: CÃ¡lculos com tratamento de precisÃ£o decimal
- âš¡ **Performance**: MigraÃ§Ã£o para `kafka-python` melhorou a performance
- ğŸ”§ **UV Integration**: Gerenciamento moderno de dependÃªncias

## ğŸ“‹ Comandos Ãšteis

### Desenvolvimento
```bash
# Setup inicial completo
git clone <URL_DO_REPO>
cd real_time_data
uv sync

# Gerenciamento de ambiente
uv sync                    # Instalar/atualizar dependÃªncias
uv sync --reinstall        # Reinstalar tudo do zero
uv add nome-da-biblioteca  # Adicionar nova dependÃªncia
uv remove nome-biblioteca  # Remover dependÃªncia
uv sync --upgrade          # Atualizar todas as dependÃªncias

# Executar testes
uv run pytest tests/ -v                           # Todos os testes
uv run pytest tests/test_csv_producer.py -v       # Testes especÃ­ficos
uv run pytest tests/ --cov=. --cov-report=html    # Com cobertura

# Executar aplicaÃ§Ãµes
uv run python csv-monitor/csv_producer.py         # Producer
uv run streamlit run streamlit/dashboard.py       # Dashboard
uv run python -m pytest tests/                    # Testes como mÃ³dulo

# Verificar ambiente
uv run python --version                           # VersÃ£o Python
uv run pip list                                   # DependÃªncias instaladas
uv tree                                           # Ãrvore de dependÃªncias
```

### Docker
```bash
# Subir serviÃ§os
docker-compose up -d

# Ver logs
docker-compose logs -f

# Parar serviÃ§os
docker-compose down

# Limpar tudo
docker-compose down --remove-orphans
docker system prune -f
```

### Monitoramento
```bash
# Ver containers rodando
docker ps

# Monitorar logs do Kafka
docker logs -f kafka

# Verificar tÃ³picos (se kafka-tools instalado)
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

**ğŸš€ Sistema completo de streaming de dados com sincronizaÃ§Ã£o total funcionando!**